---
title: "Assignment 3"
output: html_document
date: "2024-11-03"
Group3: "Julian Janisch, Hanka Jankovicova, Livia Miclaus, Sofiia Selimova, Bence Zsolt Vízvári"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We load important libraries for our assignment:
```{r}
library(ggplot2)
library(gridExtra)
library(rpart)
library(partykit)
library(grid)
library(dplyr)
library("ranger")
```

Let us read the data into R:
```{r}
df <- read.csv("housing.csv", header = TRUE, sep = ",")
```


## 1.Task:

In this first task we have to identify and remove missing values followed by a visual comparison of the marginal distribution of all features and the response before and after removing the missing values.

First, let us take a closer look at the data frame:
```{r}

#Display the first few rows and the last few rows of the dataset
head(df)
tail(df)
# The dataset appears to contain columns like longitude, latitude, housing_median_age, etc.
# These values give a quick sense of the data format and what each feature represents
# Checking the last rows confirms the data’s range and shows no unexpected end-of-file issues

# Check the structure of the dataset
str(df)
# The dataset has 20640 observations of housing data in California from the 1990 census and 10 variables, with numeric features for coordinates, age, rooms, population, income, house value and a character variable for ocean proximity


summary(df) # total_bedrooms shows 207 missing values in total

```
In summary() we observe that the median_house_value is the response (numerical) variable representing the median value of houses in various California districts. The features include geographic coordinates (longitude and latitude), housing_median_age, total_rooms, total_bedrooms, population, households, median_income of residents, and ocean_proximity, which indicates the house’s distance from the ocean. We also observe that there are 207 missing values in total_bedrooms, which we'll handle in subsequent steps.


We split the data into numeric and categorical variables:
```{r}
numeric_names <- names(df)[sapply(df, is.numeric)]
categorical_names <- names(df)[sapply(df, is.character)]
```


We create a modified version of df with placeholder values for NULL entries in numeric columns. Only the total_bedrooms column contains NULL values, so we add a placeholder (-1) specifically for it. This modified data will allow us to visualize and compare distributions with and without missing values:
```{r}
df_with_na <- df %>%
  mutate(across(all_of(numeric_names), ~ ifelse(is.na(.), -1, .))) 
```

We define two functions for creating the plots:
```{r}
plot_numeric <- function(data, feat){
  ggplot(data, aes_string(x = feat)) + 
    geom_histogram(aes(y = after_stat(density)),
                   fill = "green", 
                   color = "black",
                   alpha = 0.7) + 
    geom_density(color = "black") + 
    theme_minimal() +
    labs(title = paste("Distribution of", feat))
}

plot_categorical <- function(data, feat){
  ggplot(data, aes_string(x = feat)) + 
    geom_bar(fill = "green", 
             color = "black",
             alpha = 0.7) + 
    theme_minimal() +
    labs(title = paste("Distribution of", feat))
}
```


We loop over all columns to create plots for the data with placeholders for missing values. The plots are saved in plots_before so we can see each feature's distribution before dealing with the missing values:
```{r}
plots_before <- list()
for(feat in numeric_names){
  plots_before[[feat]] <- plot_numeric(df_with_na, feat)
}
for(feat in categorical_names){
  plots_before[[feat]] <- plot_categorical(df_with_na, feat)
}

```


Next step is to remove the NULL values:
```{r}
df1 <- na.omit(df)  # Dataset without missing values 
```


In this chunk, we create plots for data without missing values and store them in plots_after. We then pair each "before" and "after" plot for each feature side-by-side. These paired plots are saved in grid_plots, arranged with two columns for easier comparison of distributions before and after removing missing values:
```{r}
# Create plots for data without NA values
plots_after <- list()
for(feat in numeric_names){
  plots_after[[feat]] <- plot_numeric(df1, feat)
}
for(feat in categorical_names){
  plots_after[[feat]] <- plot_categorical(df1, feat)
}

# Arrange plots in pairs 
grid_plots <- list()
for (feat in c(numeric_names, categorical_names)) {
  grid_plots[[feat]] <- arrangeGrob(
    plots_before[[feat]], plots_after[[feat]], ncol = 2,
    top = textGrob(
      paste("Distribution of", feat, "Before and After Removing Missing Values"),
      gp = gpar(fontsize = 10)  
    )
  )
}
```

This code arranges all paired "before" and "after" plots in a grid layout:
```{r}
do.call(grid.arrange, c(grid_plots, ncol = 2))  
```


Since there are many plots, markdown tries to fit them all into a single cell, which can make them difficult to read. To make sure each plot is displayed clearly, this code chunk below will save the plots as a PDF in your working directory. In the PDF you can see the plots clear and compare them side-by-side without the overlapping issue:
```{r}
pdf("feature_distributions.pdf", width = 14, height = 20)
do.call(grid.arrange, c(grid_plots, ncol = 2))
dev.off()
```

Conclusions and interpretations:

In the total_bedrooms feature, we had missing values, making it impossible to visualize them directly. We used a placeholder as a helper to allow ggplot to display rows with missing values in other features so that we could compare their distributions before and after removing the rows with NULL values in total_bedrooms.

The distributions of all features (except total_bedrooms) show little to no change before and after removing these rows. The shape and density of the functions remain consistent, suggesting that the missing values were not clustered in any specific range. Removing these 207 rows, which is only about 1% of the dataset, did not significantly impact the overall distribution of the features.

We do not consider total_bedrooms in this comparison because it only contained NULL values. Therefore, the placeholder didn’t change its distribution.

## 2.Task:

In this task we fit a regression tree to predict median_house_value using all features:

First we convert ocean_proximity from character into factor:
```{r}
df1$ocean_proximity <- as.factor(df1$ocean_proximity)
```

Then we fit a regression tree to the cleaned data, using median_house_value as the response variable and all other features as predictors. The tree model will help us understand how different features, like income and coastal proximity, influence house values. We then plot the tree to visualize these relationships:
```{r}
tree <- rpart(median_house_value ~ ., data = df1)
plot(as.party(tree))
```
Interpretation:

This tree visualizes the relationship between the response and the chosen features median_income, ocean_proximity, and longitude. The root divides the data by median_income at 5.075, indicating that median_income is the most influential feature on median_house_value. Furthermore, the tree shows a significant effect of coastal proximity, indicating that houses near the coast tend to have a higher value than those located "INLAND". Also, longitude seems to take into account some regional effects. When examining the leaves, we see that the highest median_house_value occurs when median_income is higher than 6.887, whereas the lowest values are found when median_income is below 3.036 and the house is located in "INLAND". This indicates a strong correlation between median_income and median_house_value, with all three features having a substantial effect on house value. Longitude is considered only once and shows some differences overall.

In terms of variability and outliers, there are many outliers in median_house_value for cases where median_income < 5.075. All of these outliers appear above the boxplot, indicating that quite a few people with lower income still pay above-average prices for a house. The 'wings' of the boxplot gradually widen as median_income increases, indicating a broader price range at higher income levels. The majority of houses are in the group where median_income < 5.075 and ocean_proximity is less than 1 hour. In the group with median_income > 5.075, there are fewer cases, but the boxplots are individually wider, and there are nearly no outliers. Interestingly, the smallest group is the one with median_income > 5.075 and the house situated inland, possibly because people with higher income would rather buy a house near the ocean than inland.

## 3.Task:

In this third task, we fit a random forest model to predict median_house_value and evaluate feature importance using permutation importance scores. We will then compare these scores to the key variables identified in the regression tree from Task 2. Finally, we create a partial dependency plot for the most important feature to analyze its effect on house values.

This chunk fits a random forest model to predict median_house_value using all features in df1. We use permutation importance to see which features contribute most to the prediction, then print and plot the importance values:
```{r}
rf <- ranger(median_house_value ~ ., data = df1, probability = FALSE, importance = "permutation")
print(rf)
plot(as.table(importance(rf)), ylab = "Importance")
```
Interpretation: 

We can see from the permutation importance plot that the most important factors in the random forest model are longitude, latitude and median_income. In contrast, Task 2's regression tree identified median_income, ocean_proximity, and longitude as the most important features. Therefore, the two methods partially agree on important factors: both highlight median_income and longitude as significant predictors of median_house_value.

However, there is a difference in the third variable. The random forest model considers latitude to be highly important, while the regression tree emphasizes ocean_proximity. This distinction suggests that while both models agree on the significance of income and geographic location, they differ in how they prioritize specific aspects of location (latitude versus proximity to the ocean).


Because median_income is the most important feature (as measured by permutation importance), we produce a partial dependency plot to show its effect on median_house_value (our response).

The process includes following steps:

We define a grid over the range of median_income values and we sample 300 observations to reduce computation for predictions:
```{r}
grd <- 10^seq(min(log10(df1$median_income)), max(log10(20)), length.out = 2e1)
nd <- df1[sample.int(nrow(df1), 300), ]
```

We now calculate predictions across the grid values of median_income, keeping other features fixed:
```{r}
prs <- lapply(grd, \(val) {
  nd$median_income <- val
  predict(rf, data = nd, type = "response")$predictions[]
})
```

Finally we plot the estimated median_house_value against median_income:
```{r}
matplot(grd, t(do.call("cbind", prs)), type = "l", col = rgb(.1, .1, .1, .1),
        lty = 1, xlab = "Median_income", ylab = "Estimated median_house_value")
```
Interpretation:

The partial dependency plot illustrates the relationship between median income (x-axis) and the estimated median house value (y-axis). As observed, there is a clear positive correlation: as median income increases, the estimated median house value also tends to rise. This trend supports the intuition that properties in higher-income areas are generally more expensive.

We can also observe a plateau in house values beginning at a median income level of aprox. 10-12. After this point, higher income does not lead to much higher house values, which means that more income does not significantly increase the price of homes.

At lower income levels, the plot shows more differences in house values, indicated by the wider spread of lines. This means that in these areas, other factors besides income may also influence house prices.

## 4.Task:

In this last task, we will compare the regression tree, random forest, and linear regression models by looking at their mean squared error (MSE) from 10-fold cross-validation. This will help us see which model is the most accurate in predicting median_house_value.

First, we define the number of folds for cross-validation and initialize an empty list to store MSE for each model:
```{r}
n <- nrow(df1)
fold <- 10
folds <- sample(rep(1:fold, length.out = n))
mse <- list(tree = numeric(fold), rf = numeric(fold), lm = numeric(fold))
```

Here, we perform a cross-validation loop. For each fold, we split the data into training and test sets, fit the models on the training set, make predictions on the test set, and calculate the MSE:
```{r}

# Cross-validation loop
for (tfold in seq_len(fold)) {
  # Split data into training and test sets
  train_idx <- which(folds != tfold)
  test_idx <- which(folds == tfold)
  
  # Fit models on the training set
  rf <- ranger(median_house_value ~ ., data = df1[train_idx, ], importance = "permutation")
  tree <- rpart(median_house_value ~ ., data = df1[train_idx, ], method = "anova")
  lm_model <- lm(median_house_value ~ ., data = df1[train_idx, ])
  
  # Make predictions on the test set
  p_rf <- predict(rf, data = df1[test_idx, ])$predictions
  p_tree <- predict(tree, newdata = df1[test_idx, ])
  p_lm <- predict(lm_model, newdata = df1[test_idx, ])
  
  # Calculate and store MSE
  actual <- df1$median_house_value[test_idx]
  mse$rf[tfold] <- mean((actual - p_rf)^2)
  mse$tree[tfold] <- mean((actual - p_tree)^2)
  mse$lm[tfold] <- mean((actual - p_lm)^2)
}

```


After the loop, we combine the MSE results for each model into a data frame to facilitate comparison:
```{r}
# Combine results into a data frame
mse_df <- data.frame(Tree = mse$tree, `Random Forest` = mse$rf, `Linear Regression` = mse$lm)
```


Finally, we create a box plot to compare the cross-validated MSE for each model. This plot helps us understand each model's performance and variability.:
```{r}
# Plot the cross-validated MSE
boxplot(mse_df, names = c("Tree", "Random Forest", "Linear Regression"),
        ylab = "Cross-validated Mean Squared Error",
        main = "Model Comparison: Cross-validated MSE")
```


Interpretation:

The boxplot shows the cross-validated MSE for the regression tree, random forest and linear regression models. We can directly compare the predictive accuracy regarding median_house-value. A lower MSE value indicates a better model performance. At the same time, the width of the boxes shows how consistent each model's predictions are across different parts of the data.

The random forest model shows the lowest median MSE and a very narrow interquartile range, suggesting that it provides the most accurate predictions. Random forests typically do not overfit, even with many features, and they usually deliver strong predictions with minimal need for tuning. They generally perform better than a single pruned tree and are often a reliable benchmark to compare against for prediction tasks.

The regression tree has the highest median MSE and the most variation in its predictions, making it the worst-performing model among the three. While it can capture complex relationships, it is sensitive to changes in the training data, which can lead to overfitting. This means it often picks up on noise rather than the main patterns, making it less reliable and accurate for new data.

The linear regression model has a median MSE that is higher than that of the random forest but lower than the regression tree. The variability in MSE for linear regression is smaller than that for the regression tree but larger than that for the random forest. The middle position of the linear regression model indicates a balanced performance — it is a reasonable choice for prediction but not the best option when compared to more complex models like random forests.

If we were to choose between these models, the random forest would be the best pick, as it provides the lowest MSE and the most accurate predictions.